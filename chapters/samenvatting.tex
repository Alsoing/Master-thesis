Diepe neurale netwerken (DNN's) hebben toonaangevende prestaties geleverd bij verschillende computervisietaken. Niettemin zijn ze door hun aanzienlijke reken- en geheugenvereisten niet geschikt voor omgevingen met beperkte middelen, zoals ruimtemissies. In deze context worden strenge beperkingen op het gebied van stroomverbruik, verwerkingsdoorvoer en opslagcapaciteit nog verder verscherpt door hoge niveaus van ioniserende straling. Deze straling kan bitflipping in modelgewichten of activeringswaarden veroorzaken, wat tot kritieke storingen kan leiden. In deze studie wordt het verband onderzocht tussen modelparameterreductie (gemeten aan de hand van het aantal bespaarde drijvende-kommabewerkingen) en nauwkeurigheidsverlies bij systematische foutinjectie. Het doel van dit onderzoek is om de fouttolerantie van verschillende complexiteitspruningmodellen te onderzoeken. Er wordt specifiek gestructureerde pruning toegepast op grote en kleine convolutional architecturen (bijv. VGG en CCDF), waarbij de injectie van eenheidsfouten wordt gecontroleerd op basis van het aantal drijvende-kommabewerkingen in het model. De experimentele bevindingen tonen aan dat omvangrijke convolutional modellen, zoals VGG-16, veerkrachtig zijn bij gestructureerde pruning, met een maximale tolerantie van 50\% pruning, waarbij de nauwkeurigheid minimaal afneemt bij blootstelling aan door straling veroorzaakte fouten. Omgekeerd vertonen compacte modellen, zoals CCDF\_MNIST, een aanzienlijke nauwkeurigheidsdaling van meer dan 20 procentpunten wanneer ze worden onderworpen aan snoei van meer dan 30\%. Deze bevindingen bevestigen de duidelijke afweging tussen modelcompressie en fouttolerantie, en bieden daarmee bruikbare richtlijnen voor het ontwerp van AI-systemen voor de lucht- en ruimtevaart.
